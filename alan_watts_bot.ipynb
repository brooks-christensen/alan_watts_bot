{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395\n",
      "./data/Alan Watts HUGE Collection/Zencast92.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD08 - The World Just So - Part 2/Alan Watts - 03 - The in defines the out defines the in.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD08 - The World Just So - Part 2/Alan Watts - 02 - Escaping the tangle.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD08 - The World Just So - Part 2/Alan Watts - 07 - Seeing past the illusion.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD08 - The World Just So - Part 2/Alan Watts - 06 - Answering the koan.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD08 - The World Just So - Part 2/Alan Watts - 04 - The Japanese Zen monastery.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD08 - The World Just So - Part 2/Alan Watts - 05 - Entering the temple.mp3\n",
      "./data/Alan Watts HUGE Collection/09 Philosophy of the Tao/Alan Watts  - 09 02 Philosophy of the Tao - Philosophy of the Tao 3 and 4.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD06 - The Inevitable Ecstacy - Part 2/Alan Watts - 08 - Every incarnation is this one.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD06 - The Inevitable Ecstacy - Part 2/Alan Watts - 02 - Seeing beyond the game.mp3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "mp3_file_list = []\n",
    "\n",
    "for root, dirs, files in os.walk('.'):\n",
    "    for file in files:\n",
    "        if file.endswith('.mp3'):\n",
    "            mp3_file_list.append(os.path.join(root, file))\n",
    "\n",
    "print(len(mp3_file_list))\n",
    "\n",
    "for file in mp3_file_list[:10]:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/Alan Watts HUGE Collection/Alan Watts - Still The Mind - Introduction To Meditation/alan watts - introduction to meditation - 9.mp3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "smallest_file = min(mp3_file_list, key=os.path.getsize)\n",
    "print(smallest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for root, dirs, files in os.walk('.'):\n",
    "    for file in files:\n",
    "        # if file.endswith('.ogg'):\n",
    "        # if file.endswith('.png'):\n",
    "        if file.endswith('.afpk'):\n",
    "            os.remove(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcribe Recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1.42G/1.42G [01:49<00:00, 13.9MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Now, can you actually hear anyone who is listening?\n",
      "Can you hear any difference between all these sounds on the one hand and yourself on the other?\n",
      "Now, when you were about to absorb into the sound, where were you?\n",
      "This would be called a state of consciousness, where we have a primitive form of samadhi.\n",
      "That is to say, we are happily absorbed in what we are doing, and we have forgotten about ourselves.\n",
      "You can't very well do that and worry, or think anything serious.\n",
      "And you'll notice that there's a special way of doing it, because, I mean, we can go crazy, and we can do kind of the wild Indian chants.\n",
      "But in this, you are sort of straining too much, as a rule.\n",
      "If you keep it down to a soft thing, like this, and get that flating feeling of the voice, if you instantly feel any sound is uncomfortable, avoid it.\n",
      "Slip down if you're going too high, slip up if you're getting too low.\n",
      "If your voice tends to change, follow its change.\n",
      "So that you're just swinging along with it.\n",
      "This is the point of why, from ancient times, people discovered humming and singing, and everybody used to sing while they were.\n",
      "But you will notice that today, very few people sing at all.\n",
      "You have to make a thing of it.\n",
      "People are afraid of their voices, their melodic voice is distinct from the spoken voice.\n",
      "I know an enormous number of people who never sing at all.\n",
      "Why is it that when the scriptures, the Upanishads, the Sutras, are read, they are invariably chanted?\n",
      "Because an extra dimension is added to the voice as soon as you bring a note into it.\n",
      "That's the divine element, you see, the note sound, the singing sound, symbolically speaking.\n",
      "So this is a form of what I would call free mantra chanting, like we did it then, which isn't used much.\n",
      "But it does give you, as you do it, a very good idea of what the meditative state is.\n",
      "Because it isn't just the lettings happen, only the things going on around that's inside you as well, as distinct from the prescribed mantra, like om mani padme hum, or om ah um, or om ram shri ram, jai jai ram, hari krishnan, hari krishnan, krishn krishnan, hari hari, etc.\n",
      "Each one of them has a different feeling to it.\n",
      "The Tibetan monks go down to an extraordinarily deep sound.\n",
      "They go as deep as you can get.\n",
      "There is a reason for this.\n",
      "That's very difficult to explain, because you have to do it.\n",
      "When you go down into sound as deeply as you can get, you're going to an extreme of the vibration.\n",
      "And everybody feels naturally that what is deep is sort of the underpinnings, the foundation.\n",
      "And when they go into that deep sound, they are literally exploring the depth of sound.\n",
      "As we say, go into it deeply.\n",
      "But you can very readily see once you get into that, that you're in another state of consciousness altogether.\n",
      "You're not anymore impugnately tethering to your skull everyday consciousness.\n",
      "What I call normal restlessness.\n",
      "But in this way, you always get a sensuous feeling of the breath, that it's very enjoyable to breathe.\n",
      "And then you will find this will help in the quality of the sound you produce.\n",
      "And we of course have to get away from some of our musical prejudices when we do this.\n",
      "Now, I know, I'm sorry, but everybody thinks that to spend a lot of time gently humming nonsens to yourself is a waste of time.\n",
      "What are you going to do with the time that you save?\n",
      "But the point though is, with all this, the first thing we have to understand is what I would call deep listening.\n",
      "And very few people ever really listen.\n",
      "Because instead of receiving the sound, they make comments on it all the time.\n",
      "They're thinking about it.\n",
      "And so the sound is never fully heard.\n",
      "You just have to let it take over.\n",
      "Let it take you over completely.\n",
      "Then you get the samadhi state of becoming it.\n",
      "And it also means that you abandon your socially nervous personality.\n",
      "Where one of the reasons why people don't sing is that they hear so many masters on records and they're ashamed of their own voices.\n",
      "And think there's no point singing unless I'm good at it.\n",
      "Well, that's like saying there's no point in my doing anything at all unless I'm particularly gifted at it, which is ridiculous.\n",
      "But singing is of course very good for you, but we won't mention that, but it brings in too much purposefulness into it.\n",
      "And it's like a child will make noises because of the absorbing interest of making noises.\n",
      "The child will make noises like this.\n",
      "See?\n",
      "To explore the possibilities of what you can do with a voice.\n",
      "See?\n",
      "Ha!\n",
      "You don't see ourselves going around there.\n",
      "Oh, be sorry.\n",
      "Oh, we are not.\n",
      "Enjoy it.\n",
      "See?\n",
      "You're having the fun.\n",
      "All this is perfectly incomparable with the meditation.\n",
      "It embarrasses the fellow.\n",
      "What are you laughing at?\n",
      "I don't see any point in laughing at something funny.\n",
      "I had a friend who was a theological student.\n",
      "He was very fat.\n",
      "And he used to sit on the elevated train that went from Evanston into Chicago.\n",
      "He'd go to the seats right down the side of the train so he'd sit in the middle of one side and everybody in the car could see him.\n",
      "He was fat while they were sitting and you'd get on at Evanston.\n",
      "It's the best.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"medium\")\n",
    "# result = model.transcribe(mp3_file_list[0])\n",
    "result = model.transcribe(\"./data/Alan Watts HUGE Collection/Alan Watts - Still The Mind - Introduction To Meditation/alan watts - introduction to meditation - 8.mp3\")\n",
    "print(result[\"text\"].replace('. ', '.\\n').replace('? ', '?\\n').replace('! ', '!\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/Alan Watts HUGE Collection/Zencast92.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD08 - The World Just So - Part 2/Alan Watts - 03 - The in defines the out defines the in.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD08 - The World Just So - Part 2/Alan Watts - 02 - Escaping the tangle.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD08 - The World Just So - Part 2/Alan Watts - 07 - Seeing past the illusion.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD08 - The World Just So - Part 2/Alan Watts - 06 - Answering the koan.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD08 - The World Just So - Part 2/Alan Watts - 04 - The Japanese Zen monastery.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD08 - The World Just So - Part 2/Alan Watts - 05 - Entering the temple.mp3\n",
      "./data/Alan Watts HUGE Collection/09 Philosophy of the Tao/Alan Watts  - 09 02 Philosophy of the Tao - Philosophy of the Tao 3 and 4.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD06 - The Inevitable Ecstacy - Part 2/Alan Watts - 08 - Every incarnation is this one.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD06 - The Inevitable Ecstacy - Part 2/Alan Watts - 02 - Seeing beyond the game.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD06 - The Inevitable Ecstacy - Part 2/Alan Watts - 09 - The state of nothing.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD06 - The Inevitable Ecstacy - Part 2/Alan Watts - 06 - This is the game.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD06 - The Inevitable Ecstacy - Part 2/Alan Watts - 07 - So what's the problem-.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD06 - The Inevitable Ecstacy - Part 2/Alan Watts - 04 - The illusion of the ego.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD06 - The Inevitable Ecstacy - Part 2/Alan Watts - 03 - The conspiracy we play on ourselves.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD06 - The Inevitable Ecstacy - Part 2/Alan Watts - 10 - The line of least resistance.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD06 - The Inevitable Ecstacy - Part 2/Alan Watts - 05 - The meaningless life.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Meditation/20 alan watts meditation.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Meditation/01 alan watts meditation.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Meditation/18 alan watts meditation.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Meditation/10 alan watts meditation.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Meditation/11 alan watts meditation.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Meditation/14 alan watts meditation.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Meditation/02 alan watts meditation.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Meditation/19 alan watts meditation.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Meditation/12 alan watts meditation.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Meditation/17 alan watts meditation.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Meditation/09 alan watts meditation.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Meditation/08 alan watts meditation.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Meditation/03 alan watts meditation.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Meditation/05 alan watts meditation.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Meditation/04 alan watts meditation.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Meditation/13 alan watts meditation.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Meditation/15 alan watts meditation.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Meditation/07 alan watts meditation.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Meditation/06 alan watts meditation.mp3\n",
      "./data/Alan Watts HUGE Collection/12 Images of God/Alan Watts  - 12 04 Images of God - The Joker [3of6].mp3\n",
      "./data/Alan Watts HUGE Collection/12 Images of God/Alan Watts  - 12 02 Images of God - Out of theTrap1.mp3\n",
      "./data/Alan Watts HUGE Collection/04 Buddhism Religion of No Religion/Alan Watts  - 04 05 Buddhism Religion of No Religion - Wisdom of the Mountains.mp3\n",
      "./data/Alan Watts HUGE Collection/04 Buddhism Religion of No Religion/Alan Watts  - 04 01 Buddhism Religion of No Religion - Journey From India II.mp3\n",
      "./data/Alan Watts HUGE Collection/04 Buddhism Religion of No Religion/Alan Watts  - 04 07 Buddhism Religion of No Religion - Diamond Way.mp3\n",
      "./data/Alan Watts HUGE Collection/04 Buddhism Religion of No Religion/Alan Watts  - 04 06 Buddhism Religion of No Religion - Trancending Duality.mp3\n",
      "./data/Alan Watts HUGE Collection/04 Buddhism Religion of No Religion/Alan Watts  - 04 03 Buddhism Religion of No Religion - Buddhism as Dialogue.mp3\n",
      "./data/Alan Watts HUGE Collection/04 Buddhism Religion of No Religion/Alan Watts  - 04 02 Buddhism Religion of No Religion - The middle way.mp3\n",
      "./data/Alan Watts HUGE Collection/04 Buddhism Religion of No Religion/Alan Watts  - 04 01 Buddhism Religion of No Religion - Journey From India I.mp3\n",
      "./data/Alan Watts HUGE Collection/04 Buddhism Religion of No Religion/Alan Watts  - 04 04 Buddhism Religion of No Religion - Religion of No Religion.mp3\n",
      "./data/Alan Watts HUGE Collection/08 Philosophy and Society II/Alan Watts  - 08 01 Philosophy and Society II - On Time and Death.mp3\n",
      "./data/Alan Watts HUGE Collection/08 Philosophy and Society II/Alan Watts  - 08 06 Philosophy and Society II - The Smell of Burnt Almonds.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Buddhism/No Religion I.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Buddhism/Journey From India II.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Buddhism/Middle Way II.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Buddhism/No Religion II.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Buddhism/Middle Way I.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Buddhism/Journey From India I.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Buddhism/Buddhism as Dialogue I.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Buddhism/Buddhism as Dialogue II.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Buddhism/Diamond Way.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD01 - The Nature Of Consciousness - Part 1/Alan Watts - 04 - The myth of the automatic universe.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD01 - The Nature Of Consciousness - Part 1/Alan Watts - 08 - Whose game is it.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD01 - The Nature Of Consciousness - Part 1/Alan Watts - 05 - A wiggly world.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD01 - The Nature Of Consciousness - Part 1/Alan Watts - 07 - An independant system.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD01 - The Nature Of Consciousness - Part 1/Alan Watts - 06 - A game that's worth the candle.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD01 - The Nature Of Consciousness - Part 1/Alan Watts - 09 - The world as a drama.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD01 - The Nature Of Consciousness - Part 1/Alan Watts - 03 - The myth of the ceramic construct.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD01 - The Nature Of Consciousness - Part 1/Alan Watts - 02 - Our image of the world.mp3\n",
      "./data/Alan Watts HUGE Collection/Unsorted/Alan Watts - Diamond Way.mp3\n",
      "./data/Alan Watts HUGE Collection/Unsorted/Alan Watts - Sex in the Church I.mp3\n",
      "./data/Alan Watts HUGE Collection/Unsorted/Alan Watts - Zen Tales.mp3\n",
      "./data/Alan Watts HUGE Collection/Unsorted/Alan Watts - Spiritual Authority II.mp3\n",
      "./data/Alan Watts HUGE Collection/Unsorted/Alan Watts - The Human Game i.mp3\n",
      "./data/Alan Watts HUGE Collection/Unsorted/Alan Watts - Nonsense.mp3\n",
      "./data/Alan Watts HUGE Collection/Unsorted/Alan Watts - The Human Game iii.mp3\n",
      "./data/Alan Watts HUGE Collection/Unsorted/Alan Watts - Transcending.mp3\n",
      "./data/Alan Watts HUGE Collection/Unsorted/Alan Watts - The Human Game ii.mp3\n",
      "./data/Alan Watts HUGE Collection/Unsorted/Alan Watts - Sex in the Church II.mp3\n",
      "./data/Alan Watts HUGE Collection/Unsorted/Alan Watts - Democracy in the Kingdom II.mp3\n",
      "./data/Alan Watts HUGE Collection/Unsorted/Alan Watts - Wisdom of the Mtns II.mp3\n",
      "./data/Alan Watts HUGE Collection/Unsorted/Alan Watts - Buddhism as Dialogue II.mp3\n",
      "./data/Alan Watts HUGE Collection/Unsorted/Alan Watts - Zen & The Limits Of Explanation.mp3\n",
      "./data/Alan Watts HUGE Collection/Unsorted/Alan Watts - Early Chinese Zen.mp3\n",
      "./data/Alan Watts HUGE Collection/Unsorted/Alan Watts - We As Organism - pt1.mp3\n",
      "./data/Alan Watts HUGE Collection/Unsorted/Alan Watts - Spiritual Authority I.mp3\n",
      "./data/Alan Watts HUGE Collection/Unsorted/Alan Watts - Democracy in the Kingdom I.mp3\n",
      "./data/Alan Watts HUGE Collection/Unsorted/Alan Watts - Coincidence.mp3\n",
      "./data/Alan Watts HUGE Collection/Unsorted/Alan Watts - Images.mp3\n",
      "./data/Alan Watts HUGE Collection/Unsorted/Alan Watts - Wisdom of the Mtns I.mp3\n",
      "./data/Alan Watts HUGE Collection/Unsorted/Alan Watts - Buddhism as Dialogue I.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Tao Of Philosophy/Nature 1.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Tao Of Philosophy/Limits 1.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Tao Of Philosophy/Relevance I.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Tao Of Philosophy/Myth  2.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Tao Of Philosophy/See Net 1.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Tao Of Philosophy/Relevance II.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Tao Of Philosophy/See Net 2.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Tao Of Philosophy/Myth 1.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Tao Of Philosophy/Limits 2.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Tao Of Philosophy/Nature 2.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of The Trap/[audio book] alan watts - out of the trap (2 of 4).mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of The Trap/[audio book] alan watts - out of the trap (1 of 4).mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of The Trap/[audio book] alan watts - out of the trap (4 of 4).mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of The Trap/[audio book] alan watts - out of the trap (3 of 4).mp3\n",
      "./data/Alan Watts HUGE Collection/10 Way Beyond the West/Alan Watts  - 10 12 Way Beyond the West- Talks with Mrs. Huxley.mp3\n",
      "./data/Alan Watts HUGE Collection/10 Way Beyond the West/Alan Watts  - 10 07 Way Beyond the West - Buddhist Fundamentals (entire).mp3\n",
      "./data/Alan Watts HUGE Collection/10 Way Beyond the West/Alan Watts  - 10 11 Way Beyond the West - Return to the Forest.mp3\n",
      "./data/Alan Watts HUGE Collection/10 Way Beyond the West/Alan Watts  - 10 02 Way Beyond the West - The Constitution of Nature.mp3\n",
      "./data/Alan Watts HUGE Collection/10 Way Beyond the West/Alan Watts  - 10 09 Way Beyond the West - Buddhist Mysticism.mp3\n",
      "./data/Alan Watts HUGE Collection/10 Way Beyond the West/Alan Watts  - 10 05 Way Beyond the West - The Game Of Yes & No-pt2.mp3\n",
      "./data/Alan Watts HUGE Collection/10 Way Beyond the West/Alan Watts  - 10 05 Way Beyond the West - The Game Of Yes & No (1 of 2).mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD10 - The World As Self - Part 2/Alan Watts - 06 - The role of the trickster.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD10 - The World As Self - Part 2/Alan Watts - 12 - A place for the hermit.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD10 - The World As Self - Part 2/Alan Watts - 05 - The limits of self-awareness.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD10 - The World As Self - Part 2/Alan Watts - 11 - Gamesmanship in spiritual practice.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD10 - The World As Self - Part 2/Alan Watts - 02 - The human world as self.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD10 - The World As Self - Part 2/Alan Watts - 09 - The Yoga Sutra.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD10 - The World As Self - Part 2/Alan Watts - 04 - Shedding the masks.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD10 - The World As Self - Part 2/Alan Watts - 07 - The journey to where you already are.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD10 - The World As Self - Part 2/Alan Watts - 08 - Fear of enlightenment.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD10 - The World As Self - Part 2/Alan Watts - 03 - Stages of citizenship in India.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD10 - The World As Self - Part 2/Alan Watts - 10 - How not to use the mind.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - The Veil Of/2.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - The Veil Of/1.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - The Joker/1b.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - The Joker/2a.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - The Joker/2b.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - The Joker/1a.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - The Joker/3b.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - The Joker/3a.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Zen And The Contolled Accident/c755-2 zen and the controlled accident.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Zen And The Contolled Accident/c755-1 zen and the controlled accident.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Zen And The Contolled Accident/c755-3 zen and the controlled accident.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Zen And The Contolled Accident/c755-4 zen and the controlled accident.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Myth And Religion/Image of Man II.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Myth And Religion/Democracy in the Kingdom I.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Myth And Religion/Not What Should Be I.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Myth And Religion/Jesus, His Religion I.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Myth And Religion/Not What Should Be II.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Myth And Religion/Jesus, His Religion II.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Myth And Religion/Image of Man I.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Myth And Religion/Democracy in the Kingdom II.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD12 - The World As Emptiness - Part 2/Alan Watts - 04 - A happy death.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD12 - The World As Emptiness - Part 2/Alan Watts - 05 - Raising the alarm.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD12 - The World As Emptiness - Part 2/Alan Watts - 09 - Thunderous silence.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD12 - The World As Emptiness - Part 2/Alan Watts - 06 - The world as void.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD12 - The World As Emptiness - Part 2/Alan Watts - 03 - Willing to die.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD12 - The World As Emptiness - Part 2/Alan Watts - 08 - Consider death now.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD12 - The World As Emptiness - Part 2/Alan Watts - 02 - The Buddhist attitude of change.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD12 - The World As Emptiness - Part 2/Alan Watts - 07 - Voiding the void.mp3\n",
      "./data/Alan Watts HUGE Collection/01 The Tao of Philosophy/Alan Watts  - 01 02 The Tao of Philosophy - Images Of God.mp3\n",
      "./data/Alan Watts HUGE Collection/01 The Tao of Philosophy/Alan Watts  - 01 01 The Tao of Philosophy - Slices of Wisdom.mp3\n",
      "./data/Alan Watts HUGE Collection/01 The Tao of Philosophy/Alan Watts  - 01 06 The Tao of Philosophy - Man in Nature.mp3\n",
      "./data/Alan Watts HUGE Collection/01 The Tao of Philosophy/Alan Watts  - 01 04 The Tao of Philosophy - Seeing Through the Net.mp3\n",
      "./data/Alan Watts HUGE Collection/01 The Tao of Philosophy/Alan Watts  - 01 05 The Tao of Philosophy - Myth of Myself.mp3\n",
      "./data/Alan Watts HUGE Collection/01 The Tao of Philosophy/Alan Watts  - 01 03 The Tao of Philosophy - Coincidence of Opposites.mp3\n",
      "./data/Alan Watts HUGE Collection/01 The Tao of Philosophy/Alan Watts  - 01 07 The Tao of Philosophy - Limits of Language.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Game Theory Of Ethics/07 - game theory of ethics.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Game Theory Of Ethics/02 - game theory of ethics.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Game Theory Of Ethics/01 - game theory of ethics.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Game Theory Of Ethics/05 - game theory of ethics.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Game Theory Of Ethics/06 - game theory of ethics.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Game Theory Of Ethics/04 - game theory of ethics.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Game Theory Of Ethics/03 - game theory of ethics.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Buddhism - The Religion Of No Religion/alan watts - buddhism, religion of no religion 1#3-004.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Buddhism - The Religion Of No Religion/alan watts - buddhism, religion of no religion 1#3-016.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Buddhism - The Religion Of No Religion/alan watts - buddhism, religion of no religion 1#3-003.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Buddhism - The Religion Of No Religion/alan watts - buddhism, religion of no religion 1#3-015.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Buddhism - The Religion Of No Religion/alan watts - buddhism, religion of no religion 1#3-009.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Buddhism - The Religion Of No Religion/alan watts - buddhism, religion of no religion 1#3-005.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Buddhism - The Religion Of No Religion/alan watts - buddhism, religion of no religion 1#3-014.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Buddhism - The Religion Of No Religion/alan watts - buddhism, religion of no religion 1#3-001.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Buddhism - The Religion Of No Religion/alan watts - buddhism, religion of no religion 1#3-006.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Buddhism - The Religion Of No Religion/alan watts - buddhism, religion of no religion 1#3-012.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Buddhism - The Religion Of No Religion/alan watts - buddhism, religion of no religion 1#3-013.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Buddhism - The Religion Of No Religion/alan watts - buddhism, religion of no religion 1#3-007.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Buddhism - The Religion Of No Religion/alan watts - buddhism, religion of no religion 1#3-008.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Buddhism - The Religion Of No Religion/alan watts - buddhism, religion of no religion 1#3-010.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Buddhism - The Religion Of No Religion/alan watts - buddhism, religion of no religion 1#3-011.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Buddhism - The Religion Of No Religion/alan watts - buddhism, religion of no religion 1#3-002.mp3\n",
      "./data/Alan Watts HUGE Collection/07 Philosophy and Society/Alan Watts  - 07 06 Philosophy and Society - On Being God (Whole Thing).mp3\n",
      "./data/Alan Watts HUGE Collection/07 Philosophy and Society/Alan Watts  - 07 01 Philosophy and Society - The Veil Of Thoughts 2.mp3\n",
      "./data/Alan Watts HUGE Collection/07 Philosophy and Society/Alan Watts  - 07 01 Philosophy and Society - The Veil Of Thoughts 1.mp3\n",
      "./data/Alan Watts HUGE Collection/07 Philosophy and Society/Alan Watts  - 07 05 Philosophy and Society - Mysticism and Morals.mp3\n",
      "./data/Alan Watts HUGE Collection/07 Philosophy and Society/Alan Watts  - 07 04 Philosophy and Society - What is Reality.mp3\n",
      "./data/Alan Watts HUGE Collection/07 Philosophy and Society/Alan Watts  - 07 03 Philosophy and Society - We As Organism-pt1.mp3\n",
      "./data/Alan Watts HUGE Collection/06 Eastern and Western Zen II/Alan Watts  - 06 04 Eastern and Western Zen II - World as Just So.mp3\n",
      "./data/Alan Watts HUGE Collection/06 Eastern and Western Zen II/Alan Watts  - 06 01 Eastern and Western Zen II - Introduction to Zen.mp3\n",
      "./data/Alan Watts HUGE Collection/06 Eastern and Western Zen II/Alan Watts  - 06 02 Eastern and Western Zen II - Early Chinese Zen I.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD04 - The Web Of Life - Part 2/01 - 01 - Introduction.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD04 - The Web Of Life - Part 2/05 - 05 - The sound of rain needs no translation.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD04 - The Web Of Life - Part 2/06 - 06 - What game would you like to play.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD04 - The Web Of Life - Part 2/03 - 03 - The nature of selfishness.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD04 - The Web Of Life - Part 2/07 - 07 - Is it serious.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD04 - The Web Of Life - Part 2/04 - 04 - A perfectly genuine act.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD04 - The Web Of Life - Part 2/08 - 08 - An invitation to dance.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD04 - The Web Of Life - Part 2/02 - 02 - Web as mutuality.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Still The Mind - Introduction To Meditation/alan watts - introduction to meditation - 8.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Still The Mind - Introduction To Meditation/alan watts - introduction to meditation - 7.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Still The Mind - Introduction To Meditation/alan watts - introduction to meditation - 1.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Still The Mind - Introduction To Meditation/alan watts - introduction to meditation - 3.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Still The Mind - Introduction To Meditation/alan watts - introduction to meditation - 2.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Still The Mind - Introduction To Meditation/alan watts - introduction to meditation - 6.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Still The Mind - Introduction To Meditation/alan watts - introduction to meditation - 5.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Still The Mind - Introduction To Meditation/alan watts - introduction to meditation - 9.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Still The Mind - Introduction To Meditation/alan watts - introduction to meditation - 4.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 Meditation - The Sound of Hinduism - 02 - Tambouras for Meditation.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 I Think.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 Meditation 1.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - Whose is the Power Kingdom and Glory.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 Zen Clues - 03 - Zen Clues - 03.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - Tai Chi Chuan.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 Lecture on GK Chesterton.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts - The Future - Time in the Future - 1-01.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - Who is it who knows there is no ego.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 Lao Tzu's Tao Te Ching.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - Zen And The Limits of Explanation.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - Polar Thinking.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - Seeing Through the Game (Jung).mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - Readings from Hindu Scriptures2.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - Sahaja - 33 min.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - Classic Radio Talks - Man is a Hoax (big bang = you).mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 Insight & Ecstacy.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts - Classic Radio Talks - Daylight savings and God.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 Abstraction or Reality.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 Meditation 3.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 NYC as Manisfestation of Avolokiteshvera.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - Questioning Basic Assumptions.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - Philosophy and Society II - spectrum of love (part 1 of 2).mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 Karma of Christianity.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - Turning the Head ( On Drugs ).mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - The Solution Of The Problem Of Life.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - The Future - Time in the Future Pt 1 (entire).mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - The Way of Zen 2.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 Interview with God.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - Out Of Your Mind.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 Learning the Human Game.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts - Sahaja.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - Still The Mind - Intro To Meditation .mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - the way and its power.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - The Quaking Mess.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - Reflecting Mirror 3(inc).mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 Identical differences.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 World as Play 4  (inc).mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - Sense of Nonsense.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - Seeing 1 to 7.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 Myself, Mistaken Identity.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - Tambouras for meditation.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - More On The Future -  Future of Communication  04 (of 04).mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 Out your mind A.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 Mythology of Hinduism I.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 Meditation 10.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - The Book 1.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - The Arts - Reality Art & Illusion - 3of4.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - The Bomb (Ching and Civilization).mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 Games of Simplicity and Complexity.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 OM - The Sound of Hinduism - 03 - Readings from Hindu scriptures.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - Whole Thing.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 AUTOBIOGRAPHY.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - Classic Radio Talks - Symbols and Meaning.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 World as Play 3 (inc).mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 Meditation 2.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - Still the Mind.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - The Game Theory of Ethics.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - Classic Radio Talks - The Unpreachable Religion.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - Classic Radio Talks - Daylight savings and God.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 Meditation - OM2.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - Classic Radio Talks - Tribute to Carl Jung - 1961.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 Drug Abuse.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - The Arts - Reality Art & Illusion - 4of4.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - unintelligent universe.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - The Arts - Reality Art & Illusion - 2of4.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 Indras net.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - OM.mp3\n",
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - The Silent Mind.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD03 - The Web Of Life - Part 1/Alan Watts - 07 - Understanding the unitive world.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD03 - The Web Of Life - Part 1/Alan Watts - 04 - Seeing beyond our separateness.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD03 - The Web Of Life - Part 1/Alan Watts - 08 - An implicit agreement.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD03 - The Web Of Life - Part 1/Alan Watts - 03 - A spontaneous life.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD03 - The Web Of Life - Part 1/Alan Watts - 09 - To be aware of the melody.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD03 - The Web Of Life - Part 1/Alan Watts - 02 - What did you forget-.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD03 - The Web Of Life - Part 1/Alan Watts - 06 - Existence as a function of relationship.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD03 - The Web Of Life - Part 1/Alan Watts - 05 - Intervals between what happens.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Ecology & Religion/03 - allan watts - 03 ecology & religion.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Ecology & Religion/04 - allan watts - 04 ecology & religion.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Ecology & Religion/02 - allan watts - 02 ecology & religion.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Ecology & Religion/01 - allan watts - 01 ecology & religion.mp3\n",
      "./data/Alan Watts HUGE Collection/02 Philosophies of Asia/Alan Watts  - 02 04 Philosophies of Asia - Swallowing A Ball of Hot Iron.mp3\n",
      "./data/Alan Watts HUGE Collection/02 Philosophies of Asia/Alan Watts  - 02 05 Philosophies of Asia - Intellectual Yoga.mp3\n",
      "./data/Alan Watts HUGE Collection/02 Philosophies of Asia/Alan Watts  - 02 07 Philosophies of Asia - Taoist Way Of Karma.mp3\n",
      "./data/Alan Watts HUGE Collection/02 Philosophies of Asia/Alan Watts  - 02 03 Philosophies of Asia - Ecology & Religion 1.mp3\n",
      "./data/Alan Watts HUGE Collection/02 Philosophies of Asia/Alan Watts  - 02 02 -Philosophies of Asia - Mythology of Hinduism II.mp3\n",
      "./data/Alan Watts HUGE Collection/02 Philosophies of Asia/Alan Watts  - 02 03 Philosophies of Asia - Ecology & Religion 3.mp3\n",
      "./data/Alan Watts HUGE Collection/02 Philosophies of Asia/Alan Watts  - 02 03 Philosophies of Asia - Ecology & Religion 2.mp3\n",
      "./data/Alan Watts HUGE Collection/02 Philosophies of Asia/Alan Watts  - 02 03 Philosophies of Asia - Ecology & Religion 4.mp3\n",
      "./data/Alan Watts HUGE Collection/02 Philosophies of Asia/Alan Watts  - 02 01 -Philosophies of Asia - Relevance of Oriental Philosophy II.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD02 - The Nature Of Consciousness - Part 2/Alan Watts - 02 - Being aware of awareness.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD02 - The Nature Of Consciousness - Part 2/Alan Watts - 05 - Consciousness beyond our separateness.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD02 - The Nature Of Consciousness - Part 2/Alan Watts - 09 - A re-examination of common sense.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD02 - The Nature Of Consciousness - Part 2/Alan Watts - 06 - How do we define ourselves-.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD02 - The Nature Of Consciousness - Part 2/Alan Watts - 04 - The game of hide and seek.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD02 - The Nature Of Consciousness - Part 2/Alan Watts - 03 - Captivated by the drama.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD02 - The Nature Of Consciousness - Part 2/Alan Watts - 07 - What it is to see.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD02 - The Nature Of Consciousness - Part 2/Alan Watts - 08 - The road to here.mp3\n",
      "./data/Alan Watts HUGE Collection/03 Myth and Religion/Alan Watts  - 03 02 Myth and Religion - Spiritual Authority.mp3\n",
      "./data/Alan Watts HUGE Collection/03 Myth and Religion/Alan Watts  - 03 05 Myth and Religion - The Image of Man (entire).mp3\n",
      "./data/Alan Watts HUGE Collection/03 Myth and Religion/Alan Watts  - 03 01 Myth and Religion - Not What Should Be, but What Is.mp3\n",
      "./data/Alan Watts HUGE Collection/03 Myth and Religion/Alan Watts  - 03 06 Myth and Religion - Sex and the curch.mp3\n",
      "./data/Alan Watts HUGE Collection/03 Myth and Religion/Alan Watts  - 03 04 Myth and Religion - Democracy in the Kingdom of Heaven.mp3\n",
      "./data/Alan Watts HUGE Collection/03 Myth and Religion/Alan Watts  - 03 03 Myth and Religion - Jesus His Religion.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD11 - The World As Emptiness - Part 1/Alan Watts - 08 - A finger pointing at the moon.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD11 - The World As Emptiness - Part 1/Alan Watts - 07 - Presence of mind.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD11 - The World As Emptiness - Part 1/Alan Watts - 04 - The cause of suffering.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD11 - The World As Emptiness - Part 1/Alan Watts - 02 - The essence of Hinduism.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD11 - The World As Emptiness - Part 1/Alan Watts - 05 - The Eight-Fold Path.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD11 - The World As Emptiness - Part 1/Alan Watts - 11 - Peaks and valleys go together as one.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD11 - The World As Emptiness - Part 1/Alan Watts - 03 - The Four Noble Truths.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD11 - The World As Emptiness - Part 1/Alan Watts - 10 - The mystery of change.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD11 - The World As Emptiness - Part 1/Alan Watts - 06 - The Five Good Conducts.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD11 - The World As Emptiness - Part 1/Alan Watts - 09 - The nature of change.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD09 - The World As Self - Part 1/Alan Watts - 08 - The Hindu Yugas.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD09 - The World As Self - Part 1/Alan Watts - 07 - Rules of the game.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD09 - The World As Self - Part 1/Alan Watts - 05 - Self as play.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD09 - The World As Self - Part 1/Alan Watts - 02 - The totality of all being.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD09 - The World As Self - Part 1/Alan Watts - 09 - Western difficulty with Hindu mythology.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD09 - The World As Self - Part 1/Alan Watts - 04 - The fundamental I.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD09 - The World As Self - Part 1/Alan Watts - 06 - The rhythmic dance.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD09 - The World As Self - Part 1/Alan Watts - 03 - Awareness of the self.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - The Summer Of Love - The Psychedelic Experience/Alan Watts - The Summer Of Love - The Psychedelic Experience [01 Of 4].mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - The Summer Of Love - The Psychedelic Experience/Alan Watts - The Summer Of Love - The Psychedelic Experience [02 Of 4].mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - The Summer Of Love - The Psychedelic Experience/Alan Watts - The Summer Of Love - The Psychedelic Experience [03 Of 4].mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - The Summer Of Love - The Psychedelic Experience/Alan Watts - The Summer Of Love - The Psychedelic Experience [04 Of 4].mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD07 - The World Just So - Part 1/Alan Watts - 01 - Introduction.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD07 - The World Just So - Part 1/Alan Watts - 05 - The origins of Zen.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD07 - The World Just So - Part 1/Alan Watts - 04 - Direct pointing.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD07 - The World Just So - Part 1/Alan Watts - 08 - Who are you-.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD07 - The World Just So - Part 1/Alan Watts - 09 - Disturbing confusions of the mind.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD07 - The World Just So - Part 1/Alan Watts - 03 - Zen's appeal to the West.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD07 - The World Just So - Part 1/Alan Watts - 10 - Who is the thinker behind the thoughts.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD07 - The World Just So - Part 1/Alan Watts - 07 - No mind, no deliberation.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD07 - The World Just So - Part 1/Alan Watts - 06 - The golden age of Zen.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD07 - The World Just So - Part 1/Alan Watts - 02 - To say what can't be said.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Zen Clues/alan watts - zen clues - 03 - zen clues - 03.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Zen Clues/alan watts - zen clues - 02 - zen clues - 02.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Zen Clues/alan watts - zen clues - 01 - zen clues - 01.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Who Is It That Knows There Is No Ego/alan watts - who is it who knows there is no ego -001.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Who Is It That Knows There Is No Ego/alan watts - who is it who knows there is no ego -003.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Who Is It That Knows There Is No Ego/alan watts - who is it who knows there is no ego -005.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Who Is It That Knows There Is No Ego/alan watts - who is it who knows there is no ego -002.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Who Is It That Knows There Is No Ego/alan watts - who is it who knows there is no ego -004.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Who Is It That Knows There Is No Ego/alan watts - who is it who knows there is no ego -010.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Who Is It That Knows There Is No Ego/alan watts - who is it who knows there is no ego -007.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Who Is It That Knows There Is No Ego/alan watts - who is it who knows there is no ego -006.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Who Is It That Knows There Is No Ego/alan watts - who is it who knows there is no ego -008.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Who Is It That Knows There Is No Ego/alan watts - who is it who knows there is no ego -009.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Who Is It That Knows There Is No Ego/alan watts - who is it who knows there is no ego -011.mp3\n",
      "./data/Alan Watts HUGE Collection/05 Eastern and Western Zen/Alan Watts  - 05 04 Eastern and Western Zen I - Zen Bones.mp3\n",
      "./data/Alan Watts HUGE Collection/05 Eastern and Western Zen/Alan Watts  - 05 05 Eastern and Western Zen I - Biting an Iron Bull.mp3\n",
      "./data/Alan Watts HUGE Collection/05 Eastern and Western Zen/Alan Watts  - 05 01 Eastern and Western Zen I - Swimming Headless.mp3\n",
      "./data/Alan Watts HUGE Collection/05 Eastern and Western Zen/Alan Watts  - 05 06 Eastern and Western Zen I - Zen Tales.mp3\n",
      "./data/Alan Watts HUGE Collection/05 Eastern and Western Zen/Alan Watts  - 05 03 Eastern and Western Zen I - Unbleached Silk.mp3\n",
      "./data/Alan Watts HUGE Collection/05 Eastern and Western Zen/Alan Watts  - 05 02 Eastern and Western Zen I - Wisdom of the Ridiculous.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Philosophies Of Asia/Intro to Buddhism II.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Philosophies Of Asia/Intro to Buddhism I.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Philosophies Of Asia/Taoist Way I.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Philosophies Of Asia/Swallowing.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Philosophies Of Asia/Yoga.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Philosophies Of Asia/Hinduism I.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Philosophies Of Asia/Taoist Way III.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Philosophies Of Asia/Hinduism II.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Philosophies Of Asia/Taoist Way II.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Philosophies Of Asia/Ecozen.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD05 - The Inevitable Ecstacy - Part 1/Alan Watts - 06 - The sensation of happening.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD05 - The Inevitable Ecstacy - Part 1/Alan Watts - 12 - The spectrum of vibrations.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD05 - The Inevitable Ecstacy - Part 1/Alan Watts - 07 - Of pain and suffering.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD05 - The Inevitable Ecstacy - Part 1/Alan Watts - 11 - The eroticism of pain.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD05 - The Inevitable Ecstacy - Part 1/Alan Watts - 04 - The awareness of a baby.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD05 - The Inevitable Ecstacy - Part 1/Alan Watts - 02 - Undifferentiated vs differentiated awareness.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD05 - The Inevitable Ecstacy - Part 1/Alan Watts - 05 - The fallacy of misplaced correctness.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD05 - The Inevitable Ecstacy - Part 1/Alan Watts - 10 - The aversion to death.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD05 - The Inevitable Ecstacy - Part 1/Alan Watts - 03 - The marriage of an illusion to a futility.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD05 - The Inevitable Ecstacy - Part 1/Alan Watts - 09 - A natural satori.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD05 - The Inevitable Ecstacy - Part 1/Alan Watts - 08 - Must life go on and on-.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Strange Prayers/7 the end.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Strange Prayers/3 gagaku-ku.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Strange Prayers/6 metamatic ritual.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Strange Prayers/2 onion chant.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Strange Prayers/4 fingernail poem.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Strange Prayers/5 umdagumsu3udu.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Strange Prayers/1 love you.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Zen Mind Beginners Mind/zen mind beginners mind 4.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Zen Mind Beginners Mind/zen mind beginners mind 6.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Zen Mind Beginners Mind/zen mind beginners mind 5.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Zen Mind Beginners Mind/zen mind beginners mind 3.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Zen Mind Beginners Mind/zen mind beginners mind 2.mp3\n",
      "./data/Alan Watts HUGE Collection/Alan Watts - Zen Mind Beginners Mind/zen mind beginners mind 1.mp3\n",
      "./data/Alan Watts HUGE Collection/11 Zen and the Arts/Alan Watts  - 11 04 Zen and the Arts - Why Not Now.mp3\n",
      "./data/Alan Watts HUGE Collection/11 Zen and the Arts/Alan Watts  - 11 02 Zen and the Arts - Zen and the Art of Controlled Accidents.mp3\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/output.txt\", \"w\") as f:\n",
    "    for mp3_file in mp3_file_list:\n",
    "        print(mp3_file)\n",
    "\n",
    "        # transcribe the audio file\n",
    "        result = model.transcribe(mp3_file)\n",
    "\n",
    "        # append the transcription to an output file\n",
    "        f.write(\"\\n\\n\\n\")\n",
    "        f.write(result[\"text\"].replace('. ', '.\\n').replace('? ', '?\\n').replace('! ', '!\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reprocess Bad Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "model = whisper.load_model(\"large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf8018a0eaa4bc88d3e548f52af1d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - The Future - Time in the Future Pt 1 (entire).mp3\n"
     ]
    }
   ],
   "source": [
    "# bad_files_list = [\n",
    "#     \"./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD06 - The Inevitable Ecstacy - Part 2/Alan Watts - 06 - This is the game.mp3\",\n",
    "#     \"./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD06 - The Inevitable Ecstacy - Part 2/Alan Watts - 04 - The illusion of the ego.mp3\",\n",
    "#     \"./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD06 - The Inevitable Ecstacy - Part 2/Alan Watts - 05 - The meaningless life.mp3\",\n",
    "#     \"./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - Tambouras for meditation.mp3\",                         # NO USEFUL DATA\n",
    "#     \"./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 Meditation 2.mp3\",\n",
    "#     \"./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD09 - The World As Self - Part 1/Alan Watts - 07 - Rules of the game.mp3\",\n",
    "#     \"./data/Alan Watts HUGE Collection/Alan Watts - Out Of Your Mind - CD09 - The World As Self - Part 1/Alan Watts - 06 - The rhythmic dance.mp3\",\n",
    "#     \"./data/Alan Watts HUGE Collection/Alan Watts - Strange Prayers/7 the end.mp3\"                                        # NO USEFUL DATA\n",
    "# ]\n",
    "# bad_files_list = [\"./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - 0 Insight & Ecstacy.mp3\"]\n",
    "# bad_files_list = [\"./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - The Bomb (Ching and Civilization).mp3\"]\n",
    "# bad_files_list = [\n",
    "#     \"./data/Alan Watts HUGE Collection/Unsorted/Alan Watts - We As Organism - pt1.mp3\",\n",
    "#     \"./data/Alan Watts HUGE Collection/Alan Watts - Out Of The Trap/[audio book] alan watts - out of the trap (4 of 4).mp3\",\n",
    "#     \"./data/Alan Watts HUGE Collection/Alan Watts - The Veil Of/2.mp3\",\n",
    "#     # \"./data/Alan Watts HUGE Collection/Alan Watts - Game Theory Of Ethics/07 - game theory of ethics.mp3\",\n",
    "#     \"./data/Alan Watts HUGE Collection/Alan Watts - Buddhism - The Religion Of No Religion/alan watts - buddhism, religion of no religion 1#3-012.mp3\",\n",
    "#     \"./data/Alan Watts HUGE Collection/Alan Watts - Buddhism - The Religion Of No Religion/alan watts - buddhism, religion of no religion 1#3-010.mp3\",\n",
    "#     \"./data/Alan Watts HUGE Collection/Alan Watts - Buddhism - The Religion Of No Religion/alan watts - buddhism, religion of no religion 1#3-002.mp3\",\n",
    "#     \"./data/Alan Watts HUGE Collection/Alan Watts - Who Is It That Knows There Is No Ego/alan watts - who is it who knows there is no ego -005.mp3\"\n",
    "#     ]\n",
    "bad_files_list = [\n",
    "    # \"./data/Alan Watts HUGE Collection/Alan Watts - Buddhism - The Religion Of No Religion/alan watts - buddhism, religion of no religion 1#3-004.mp3\"\n",
    "    # \"./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - Tambouras for meditation.mp3\"\n",
    "    # \"./data/Alan Watts HUGE Collection/Alan Watts - Philosophies Of Asia/Taoist Way I.mp3\"\n",
    "    # \"./data/Alan Watts HUGE Collection/Alan Watts - Philosophies Of Asia/Intro to Buddhism I.mp3\"\n",
    "    # \"./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - Reflecting Mirror 3(inc).mp3\"\n",
    "    # \"./data/Alan Watts HUGE Collection/02 Philosophies of Asia/Alan Watts  - 02 07 Philosophies of Asia - Taoist Way Of Karma.mp3\"\n",
    "    \"./data/Alan Watts HUGE Collection/Misc Unsorted/Alan Watts  - The Future - Time in the Future Pt 1 (entire).mp3\"\n",
    "]\n",
    "\n",
    "with open('data/output_cleaned.txt', 'a') as f:\n",
    "    for bad_file in tqdm(bad_files_list):\n",
    "        print(bad_file)\n",
    "        f.write(\"\\n\\n\\n\")\n",
    "        result = model.transcribe(bad_file, language=\"en\")\n",
    "        print(result)\n",
    "        print('=' * 200)\n",
    "        f.write(result[\"text\"].replace('. ', '.\\n').replace('? ', '?\\n').replace('! ', '!\\n'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Starting Line Numbers for each Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the contents of output.txt\n",
    "with open(\"data/output_final.txt\", \"r\") as f:\n",
    "    output_contents = f.read()\n",
    "\n",
    "# Read the filenames from mp3_file_list.txt\n",
    "with open(\"data/mp3_file_list.txt\", \"r\") as f:\n",
    "    filenames = f.readlines()\n",
    "\n",
    "# Create a new file file_starts.txt\n",
    "with open(\"data/file_starts.txt\", \"w\") as f:\n",
    "    newline_count = 0\n",
    "    file_count = 0\n",
    "    for linenum, line in enumerate(output_contents.split('\\n')):\n",
    "        if linenum == 0:\n",
    "            continue\n",
    "        if line == '':\n",
    "            newline_count += 1\n",
    "            if newline_count == 2:\n",
    "                # if file_count == 0:\n",
    "                f.write(f\"{file_count + 1}) {linenum + 2} - {filenames[file_count]}\")\n",
    "                # else:\n",
    "                #     f.write(f\"{file_count + 1}) {linenum - 10} - {filenames[file_count]}\")\n",
    "                file_count += 1\n",
    "                newline_count = 0\n",
    "\n",
    "        # if line.startswith(' '):\n",
    "        #     print(linenum)\n",
    "        #     print(line)\n",
    "        #     file_count += 1\n",
    "        #     if file_count == 4:\n",
    "        #         break\n",
    "        #     # f.write(f\"{file_count + 1}) {linenum + 1} - {filenames[file_count]}\")\n",
    "        #     # file_count += 1\n",
    "    #     if line == '':\n",
    "    #         newline_count += 1\n",
    "    # print(linenum)\n",
    "    # print(newline_count)\n",
    "    # print(395 * 2 + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /home/peacelovephysics/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/peacelovephysics/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/peacelovephysics/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "nltk.download('words')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Get the list of English words\n",
    "english_words = set(words.words())\n",
    "\n",
    "def are_all_words_english(text):\n",
    "    # Split the text into words\n",
    "    word_list = text.split()\n",
    "\n",
    "    # Check if each word is in the list of English words\n",
    "    return all(word.lower() in english_words for word in word_list)\n",
    "\n",
    "# def contains_non_english_words(line):\n",
    "#     # Tokenize the line into words, ignoring punctuation\n",
    "#     tokens = word_tokenize(line)\n",
    "    \n",
    "#     # Filter out punctuation\n",
    "#     words_in_line = [word for word in tokens if word.isalpha()]\n",
    "    \n",
    "#     # Check if all words are in the English dictionary\n",
    "#     return any(word.lower() not in english_words for word in words_in_line)\n",
    "\n",
    "def contains_non_english_words(line):\n",
    "    # Tokenize the line into words, ignoring punctuation\n",
    "    tokens = word_tokenize(line)\n",
    "    \n",
    "    # Filter out punctuation\n",
    "    words_in_line = [word for word in tokens if word.isalpha()]\n",
    "    \n",
    "    # Find words not in the English dictionary\n",
    "    non_english_words = [word for word in words_in_line if word.lower() not in english_words]\n",
    "    \n",
    "    if non_english_words:\n",
    "        print(f\"Non-English words in line: {non_english_words}\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def filter_non_english_lines(text_lines):\n",
    "    non_english_lines = []\n",
    "    for line in text_lines:\n",
    "        if contains_non_english_words(line):\n",
    "            non_english_lines.append(line)\n",
    "    return non_english_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all lines after each set of two newlines start with a ' ' character\n",
    "# def check_file_starts(text_lines):\n",
    "#     newline_counter = 0\n",
    "#     for index, line in enumerate(text_lines):\n",
    "#         if line == '':\n",
    "#             newline_counter += 1\n",
    "#         if newline_counter == 1 and line != '':\n",
    "#             print('a', index + 1, line)\n",
    "#             newline_counter = 0\n",
    "#         if newline_counter == 2:\n",
    "#             newline_counter = 0\n",
    "#             if not line.startswith(' '):\n",
    "#                 print('b', index + 1, line)\n",
    "def check_file_starts(text_lines):\n",
    "    newline_counter = 0  # Counts consecutive newlines\n",
    "    for index, line in enumerate(text_lines):\n",
    "        if line == '':  # Empty line (newline)\n",
    "            newline_counter += 1\n",
    "        else:\n",
    "            if newline_counter == 1:  # One newline\n",
    "                if not line == '':\n",
    "                    print('single newline (a)', index + 1, line)\n",
    "            elif newline_counter == 2:  # Two consecutive newlines\n",
    "                if not line.startswith(' '):\n",
    "                    print('double newline (b)', index + 1, line)\n",
    "            # if newline_counter == 2:  # Two consecutive newlines\n",
    "            #     if not line.startswith(' '):\n",
    "            #         print('b', index + 1, line)\n",
    "            # Reset newline_counter after a non-empty line\n",
    "            newline_counter = 0\n",
    "\n",
    "# Read the contents of output_final.txt\n",
    "with open(\"data/output_final.txt\", \"r\") as f:\n",
    "    output_final_contents = f.read()\n",
    "\n",
    "# Split the contents into lines\n",
    "output_final_lines = output_final_contents.split('\\n')\n",
    "\n",
    "# Check if all lines after each set of two newlines start with a ' ' character\n",
    "check_file_starts(output_final_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        return f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Single Line Transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single line paragraph at line 24924 \n"
     ]
    }
   ],
   "source": [
    "# check for single lines that are not empty that are surrounded by empty lines\n",
    "# def check_single_lines(text_lines):\n",
    "#     line_counter = 0\n",
    "#     line_flag = False\n",
    "#     for index, line in enumerate(text_lines):\n",
    "#         if line == '':\n",
    "#             line_flag = True\n",
    "#         if line_flag and line != '':\n",
    "#             line_counter += 1\n",
    "#         if line_counter == 1 and line == '':\n",
    "#             print('single line', index + 1, line)\n",
    "#             line_counter = 0\n",
    "#             line_flag = False\n",
    "def check_single_lines(text_lines):\n",
    "    line_counter = 0\n",
    "    in_paragraph = False\n",
    "\n",
    "    for index, line in enumerate(text_lines):\n",
    "        if line == '':  # Empty line indicating end of a paragraph\n",
    "            if in_paragraph and line_counter == 1:\n",
    "                print('single line paragraph at line', index, line)  # Print if the paragraph had only one line\n",
    "            # Reset flags and counters after a paragraph ends\n",
    "            line_counter = 0\n",
    "            in_paragraph = False\n",
    "        else:  # Non-empty line, so we're in a paragraph\n",
    "            if not in_paragraph:\n",
    "                in_paragraph = True\n",
    "            line_counter += 1  # Increment line count within the paragraph\n",
    "\n",
    "text_lines = get_lines('data/output_final.txt')\n",
    "\n",
    "# print(text_lines[:5])\n",
    "\n",
    "check_single_lines(text_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800) ['sanzen']\n",
      "889) ['Im']\n",
      "950) ['Roshi']\n",
      "1198) ['aliveness', 'thats', 'Whats']\n",
      "1214) ['socalled']\n",
      "1237) ['isnt']\n",
      "1427) ['nittygritty', 'weve']\n",
      "1497) ['isnt']\n",
      "1630) ['Im', 'hocuspocus']\n",
      "2002) ['Im', 'koto']\n",
      "2290) ['nonexistence']\n",
      "3212) ['youve', 'Koyasan', 'Vajrayana', 'Mahayana', 'havent', 'theyre']\n",
      "3380) ['youve', 'Koyasan', 'Vajrayana', 'Mahayana', 'havent', 'theyre']\n",
      "3733) ['Bodhisattva', 'Mahayana', 'antiworldliness', 'nonBuddha']\n",
      "3740) ['reemphasizing', 'dont', 'dont']\n",
      "4422) ['50', 'Mahayana', 'subsect']\n",
      "5340) ['Bodhisattva', 'Mahayana', 'antiworldliness', 'nonBuddha']\n",
      "6175) ['reemphasizing', 'dont', 'dont', 'dont']\n",
      "6590) ['50', 'Mahayana', 'subsect']\n",
      "7025) ['youve', 'Koyasan', 'Vajrayana', 'Mahayana', 'havent', 'theyre']\n",
      "7452) ['Im']\n",
      "7814) ['youve', 'Koyasan', 'Vajrayana', 'Mahayana', 'havent', 'theyre']\n",
      "8013) ['dont']\n",
      "9227) ['malefemale', 'Tantric']\n",
      "9434) ['doesnt']\n",
      "9482) ['dont']\n",
      "9897) ['dont', '16000', 'crosslegged', 'Buddhas', 'theres', 'Dharmadhatu', 'interrelatedness', 'thats', 'isnt', 'dont', 'everythings', 'shouldnt', 'dont', 'dont', 'dont', 'youre', 'dont', 'wouldnt', 'thats', 'elses', 'Ive', 'isnt', 'arent', 'youre', 'youre', 'thats', 'Im', 'theres', 'dont', 'theyre', 'Adi', 'Buddhas', 'dont', 'isnt', 'Vagrayana', 'Im', 'crosssection', 'rupa', 'rupa', 'youve', 'thats', 'Spiegelberg', 'Corkys', 'linga', 'sharira', 'stula', 'sharira', 'youve', 'manovijnana', 'isnt', 'Sharjah', 'theres', 'whats', 'youre', 'isnt', 'youre', 'isnt', 'isnt', 'thats', 'elses', 'patris', 'thats', 'matris', 'Ive', 'dont', 'thats', 'dont', 'tantra', 'tantra', 'gotta', 'thats', 'tantra', 'wouldnt', 'didnt', 'thats', 'im', 'thats', 'thats', 'lifeness', 'theyre', 'theyre', 'theyre', 'theres', 'theres', 'tantric', 'Gunther']\n",
      "11822) ['theres']\n",
      "12037) ['dont']\n",
      "12058) ['50', 'Mahayana', 'subsect']\n",
      "12616) ['weve']\n",
      "13234) ['Im']\n",
      "13910) ['suchnesses']\n",
      "14342) ['dont']\n",
      "15368) ['Ive']\n",
      "16048) ['Im']\n",
      "16862) ['Ching']\n",
      "17330) ['theyre']\n",
      "17398) ['Patanjali']\n",
      "17519) ['Svadhalma', 'Vanaprastha']\n",
      "17567) ['sadhana']\n",
      "17595) ['youve', 'dont']\n",
      "17719) ['Krishnamurti']\n",
      "17782) ['weve', 'unbamboozled', 'Tudnum', 'dont', 'wouldnt', 'theres', 'Krishnamurti', 'hes', 'koan', 'koan', 'hes', 'Patanjali', 'Ive', 'lin', 'Ive', 'Jungs']\n",
      "18032) ['20th', 'theres']\n",
      "18467) ['nonexistence']\n",
      "19104) ['19th']\n",
      "19392) ['teabowl']\n",
      "21055) ['dont']\n",
      "22491) ['Mahayana']\n",
      "22670) ['youre']\n",
      "22860) ['theres']\n",
      "23877) ['youre']\n",
      "25195) ['5050']\n",
      "25434) ['youre', 'dont']\n",
      "25515) ['dont']\n",
      "25716) ['Vana']\n",
      "25787) ['socalled']\n",
      "25819) ['weve']\n",
      "26044) ['20th', 'theres']\n",
      "26123) ['Im']\n",
      "27552) ['weve']\n",
      "27829) ['theyre']\n",
      "28023) ['Im']\n",
      "28553) ['youre']\n",
      "28817) ['Ive', 'Laozi', 'Jing', 'Zhuangzi']\n",
      "30081) ['doesnt']\n",
      "30098) ['parsonnet']\n",
      "30997) ['Laozis', 'Dao', 'Jing']\n",
      "32091) ['Wilhelms']\n",
      "32450) ['Im']\n",
      "32665) ['Im']\n",
      "32998) ['Rexroth', 'KPFA', 'Lamontier']\n",
      "33164) ['socalled']\n",
      "34149) ['weve']\n",
      "34161) ['Im']\n",
      "34952) ['selfcontained']\n",
      "35574) ['Im', 'Koto']\n",
      "35701) ['Im']\n",
      "36117) ['Im']\n",
      "36919) ['selfregulating', 'selfgoverning']\n",
      "37392) ['dont']\n",
      "39380) ['youre']\n",
      "39488) ['preeducational']\n",
      "39943) ['socalled']\n",
      "39975) ['Matsue']\n",
      "40295) ['weve']\n",
      "40560) ['whats', 'yins', 'thats', 'doesnt', 'thats', 'youve', 'yins', 'yangs', 'doesnt', 'yins', 'theres', 'yangs', '63', '63', 'gigi']\n",
      "41179) ['socalled']\n",
      "41748) ['Ive']\n",
      "41885) ['Im', '1958', 'UCLA', 'LSD', 'LSD', 'dimethyltryptamine', 'thats', 'LST', 'DMT', 'psilocybin', 'theyre', 'theyre', 'selfserving', 'werent', 'doesnt', 'thats', 'drugtaking', 'supercolossal', '25', 'dollarwise', 'dont']\n",
      "42402) ['shes']\n",
      "42456) ['theres', 'Theres', 'Thats']\n",
      "42881) ['Oooh', 'Eehh', 'Ooooooh']\n",
      "43176) ['unitive']\n",
      "43875) ['isnt']\n",
      "43988) ['dont']\n",
      "44291) ['darflers', 'jungeri']\n",
      "44498) ['postів', '5CCP']\n",
      "44646) ['isnt']\n",
      "44877) ['dont']\n",
      "45275) ['reexamination']\n",
      "45378) ['hideandseek', 'youre', 'youre', 'youre', 'youre', 'youre', 'youre', 'youre', 'youre', 'youre', 'Hes']\n",
      "45606) ['satori', 'Im', 'youre']\n",
      "47053) ['dont']\n",
      "47896) ['dont', 'Im', 'didnt', '1611', 'socalled', '4004', 'thats', 'dont', 'Im', 'thats', 'psychotechnics', 'weve', 'psychotechnics', 'youre', 'youd', 'thats', 'doesnt', 'Nyssa', 'theyre', 'theyre', 'dont', 'prefiguration', 'theyre', 'theyre', 'unspiritual', 'Im']\n",
      "48222) ['onesided']\n",
      "48334) ['dukkha', 'dont', 'whats']\n",
      "48343) ['hes', 'panchasila']\n",
      "48564) ['hideandseek']\n",
      "49177) ['Im']\n",
      "49370) ['LSD']\n",
      "49652) ['doesnt']\n",
      "50003) ['youre']\n",
      "50162) ['cher', 'chu']\n",
      "50206) ['Enos']\n",
      "50875) ['theres']\n",
      "51488) ['uh']\n",
      "51748) ['doesnt']\n",
      "52410) ['Laozis', 'Dao', 'Jing']\n",
      "53357) ['theyre', 'Taoistic']\n",
      "53638) ['Ive', 'Laozi', 'Dao', 'Jing', 'Zhuangzi']\n",
      "54196) ['yana']\n",
      "54421) ['jhana']\n",
      "54931) ['jungeri']\n",
      "55617) ['deva']\n",
      "56125) ['dont']\n",
      "56265) ['dont']\n",
      "56493) ['1958', 'Carlfried', 'von', 'Dierkheim']\n",
      "56589) ['isnt']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# check if all the first lines are English\n",
    "with open(\"data/output_final.txt\", 'r') as f:\n",
    "    output_contents = f.read()\n",
    "\n",
    "with open(\"data/engmix.txt\", 'r') as f:\n",
    "    english_words = f.read().split('\\n')\n",
    "\n",
    "for linenum, line in enumerate(output_contents.split('\\n')):\n",
    "    if line.startswith(' '):\n",
    "        bad_words = []\n",
    "        for word in line.split():\n",
    "            for char in string.punctuation:\n",
    "                word = word.replace(char, '')\n",
    "            if word.lower() not in english_words:\n",
    "                bad_words.append(word)\n",
    "        if bad_words:\n",
    "            print(f\"{linenum + 1}) {bad_words}\")\n",
    "\n",
    "# lines = output_contents.split('\\n')\n",
    "\n",
    "# # Find lines with non-English words\n",
    "# non_english_lines = filter_non_english_lines(lines)\n",
    "\n",
    "# # Output the results\n",
    "# for line in non_english_lines:\n",
    "#     print(f\"Non-English line: {line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect, LangDetectException\n",
    "\n",
    "# Function to detect the language of paragraphs\n",
    "def detect_non_english(text_lines):\n",
    "    non_english_lines = []\n",
    "    \n",
    "    for index, line in enumerate(text_lines):\n",
    "        # Skip empty lines\n",
    "        if line.strip() == '':\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Detect the language of the line\n",
    "            lang = detect(line)\n",
    "            if lang != 'en':\n",
    "                non_english_lines.append((index + 1, line, lang))\n",
    "        except LangDetectException:\n",
    "            # If detection fails, log the line (it might be too short or ambiguous)\n",
    "            non_english_lines.append((index + 1, line, 'undetected'))\n",
    "    \n",
    "    return non_english_lines\n",
    "\n",
    "# Example usage\n",
    "with open('data/output_final.txt', 'r') as f:\n",
    "    text_lines = f.read().split('\\n')\n",
    "\n",
    "# Detect and list non-English paragraphs or lines\n",
    "non_english_lines = detect_non_english(text_lines)\n",
    "\n",
    "# Print out the lines with non-English content\n",
    "for line_number, content, detected_lang in non_english_lines:\n",
    "    print(f\"Line {line_number}: Detected as {detected_lang} -> {content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Incorporate Written Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "# from datasets import load_dataset\n",
    "\n",
    "# # Load pre-trained BERT tokenizer and model\n",
    "# print(\"loading tokenizer and model\")\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', clean_up_tokenization_spaces=True)\n",
    "# model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# # Load and preprocess dataset\n",
    "# print(\"loading dataset\")\n",
    "# dataset = load_dataset('text', data_files={'train': 'data/output_final.txt'}, split='train')\n",
    "\n",
    "# # def tokenize_function(examples):\n",
    "# #     return tokenizer(examples['text'], padding='max_length', truncation=True)\n",
    "\n",
    "# def tokenize_function(examples):\n",
    "#     return tokenizer(\n",
    "#         examples['text'], \n",
    "#         padding='max_length', \n",
    "#         truncation=True,\n",
    "#     )\n",
    "\n",
    "\n",
    "# print(\"tokenizing dataset\")\n",
    "# tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=['text'])\n",
    "\n",
    "# # Define training arguments\n",
    "# print(\"defining training arguments\")\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir='./results',\n",
    "#     num_train_epochs=3,\n",
    "#     per_device_train_batch_size=8,\n",
    "#     per_device_eval_batch_size=8,\n",
    "#     warmup_steps=500,\n",
    "#     weight_decay=0.01,\n",
    "#     logging_dir='./logs',\n",
    "# )\n",
    "\n",
    "# # Initialize Trainer\n",
    "# print(\"initializing trainer\")\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenized_datasets['train'],\n",
    "# )\n",
    "\n",
    "# # Fine-tune the model\n",
    "# print(\"fine-tuning model\")\n",
    "# trainer.train()\n",
    "\n",
    "# # Save the fine-tuned model\n",
    "# print(\"saving model\")\n",
    "# model.save_pretrained('./fine-tuned-bert')\n",
    "# tokenizer.save_pretrained('./fine-tuned-bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "# from datasets import load_dataset, DatasetDict\n",
    "\n",
    "# # Load pre-trained BERT tokenizer and model\n",
    "# print(\"loading tokenizer and model\")\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', clean_up_tokenization_spaces=True)\n",
    "# model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# # Load and preprocess dataset\n",
    "# print(\"loading dataset\")\n",
    "# dataset = load_dataset('text', data_files={'train': 'data/output_final.txt'}, split='train')\n",
    "\n",
    "# def tokenize_function(examples):\n",
    "#     return tokenizer(\n",
    "#         examples['text'], \n",
    "#         padding='max_length', \n",
    "#         truncation=True,\n",
    "#     )\n",
    "\n",
    "# # Calculate the split indices\n",
    "# total_size = len(dataset)\n",
    "# train_size = int(0.8 * total_size)  # 80% for training\n",
    "# val_size = int(0.1 * total_size)    # 10% for validation\n",
    "# test_size = total_size - train_size - val_size  # 10% for testing\n",
    "\n",
    "# # Create the splits manually without shuffling\n",
    "# train_dataset = dataset.select(range(train_size))\n",
    "# val_dataset = dataset.select(range(train_size, train_size + val_size))\n",
    "# test_dataset = dataset.select(range(train_size + val_size, total_size))\n",
    "\n",
    "# # Combine into a DatasetDict\n",
    "# final_dataset = DatasetDict({\n",
    "#     'train': train_dataset,\n",
    "#     'validation': val_dataset,\n",
    "#     'test': test_dataset\n",
    "# })\n",
    "\n",
    "# # Tokenize the datasets\n",
    "# print(\"tokenizing dataset\")\n",
    "# tokenized_datasets = final_dataset.map(tokenize_function, batched=True, remove_columns=['text'])\n",
    "\n",
    "# # Define training arguments\n",
    "# print(\"defining training arguments\")\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir='./results',\n",
    "#     num_train_epochs=3,\n",
    "#     per_device_train_batch_size=8,\n",
    "#     per_device_eval_batch_size=8,\n",
    "#     warmup_steps=500,\n",
    "#     weight_decay=0.01,\n",
    "#     logging_dir='./logs',\n",
    "#     evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
    "#     save_strategy=\"epoch\",        # Save the model at the end of each epoch\n",
    "#     load_best_model_at_end=True,  # Load the best model when done\n",
    "#     metric_for_best_model=\"accuracy\",  # Use accuracy to select the best model\n",
    "# )\n",
    "\n",
    "# # Initialize Trainer\n",
    "# print(\"initializing trainer\")\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenized_datasets['train'],\n",
    "#     eval_dataset=tokenized_datasets['validation'],  # Add validation dataset for monitoring\n",
    "# )\n",
    "\n",
    "# # Fine-tune the model\n",
    "# print(\"fine-tuning model\")\n",
    "# trainer.train()\n",
    "\n",
    "# # Evaluate the model on the test set\n",
    "# print(\"evaluating model\")\n",
    "# results = trainer.evaluate(tokenized_datasets['test'])\n",
    "\n",
    "# print(f\"Test set results: {results}\")\n",
    "\n",
    "# # Save the fine-tuned model\n",
    "# print(\"saving model\")\n",
    "# model.save_pretrained('./fine-tuned-bert')\n",
    "# tokenizer.save_pretrained('./fine-tuned-bert')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer, BertForMaskedLM, Trainer, TrainingArguments\n",
    "# from datasets import load_dataset, DatasetDict\n",
    "\n",
    "# # Load pre-trained BERT tokenizer and model\n",
    "# print(\"loading tokenizer and model\")\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', clean_up_tokenization_spaces=True)\n",
    "# model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# # Load and preprocess dataset\n",
    "# print(\"loading dataset\")\n",
    "# dataset = load_dataset('text', data_files={'train': 'data/output_final.txt'}, split='train')\n",
    "\n",
    "# # Calculate the split indices\n",
    "# total_size = len(dataset)\n",
    "# train_size = int(0.8 * total_size)  # 80% for training\n",
    "# val_size = int(0.1 * total_size)    # 10% for validation\n",
    "# test_size = total_size - train_size - val_size  # 10% for testing\n",
    "\n",
    "# # Create the splits manually without shuffling\n",
    "# train_dataset = dataset.select(range(train_size))\n",
    "# val_dataset = dataset.select(range(train_size, train_size + val_size))\n",
    "# test_dataset = dataset.select(range(train_size + val_size, total_size))\n",
    "\n",
    "# # Combine into a DatasetDict\n",
    "# final_dataset = DatasetDict({\n",
    "#     'train': train_dataset,\n",
    "#     'validation': val_dataset,\n",
    "#     'test': test_dataset\n",
    "# })\n",
    "\n",
    "# # Tokenize the datasets\n",
    "# print(\"tokenizing dataset\")\n",
    "# def tokenize_function(examples):\n",
    "#     return tokenizer(\n",
    "#         examples['text'], \n",
    "#         padding='max_length', \n",
    "#         truncation=True,\n",
    "#         max_length=512,  # or another length that makes sense for your data\n",
    "#         return_special_tokens_mask=True  # useful for masked language modeling\n",
    "#     )\n",
    "\n",
    "# tokenized_datasets = final_dataset.map(tokenize_function, batched=True, remove_columns=['text'])\n",
    "\n",
    "# # Define training arguments\n",
    "# print(\"defining training arguments\")\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir='./results',\n",
    "#     num_train_epochs=3,\n",
    "#     per_device_train_batch_size=8,\n",
    "#     per_device_eval_batch_size=8,\n",
    "#     warmup_steps=500,\n",
    "#     weight_decay=0.01,\n",
    "#     logging_dir='./logs',\n",
    "#     evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
    "#     save_strategy=\"epoch\",        # Save the model at the end of each epoch\n",
    "#     load_best_model_at_end=True,  # Load the best model when done\n",
    "# )\n",
    "\n",
    "# # Initialize Trainer\n",
    "# print(\"initializing trainer\")\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenized_datasets['train'],\n",
    "#     eval_dataset=tokenized_datasets['validation'],  # Add validation dataset for monitoring\n",
    "# )\n",
    "\n",
    "# # Fine-tune the model\n",
    "# print(\"fine-tuning model\")\n",
    "# trainer.train()\n",
    "\n",
    "# # Evaluate the model on the test set\n",
    "# print(\"evaluating model\")\n",
    "# results = trainer.evaluate(tokenized_datasets['test'])\n",
    "\n",
    "# print(f\"Test set results: {results}\")\n",
    "\n",
    "# # Save the fine-tuned model\n",
    "# print(\"saving model\")\n",
    "# model.save_pretrained('./fine-tuned-bert')\n",
    "# tokenizer.save_pretrained('./fine-tuned-bert')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer and model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset\n",
      "tokenizing dataset\n",
      "defining training arguments\n",
      "initializing trainer\n",
      "fine-tuning model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58340' max='58340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58340/58340 103:25:56, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.173200</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.042100</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.870700</td>\n",
       "      <td>1.850390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.777400</td>\n",
       "      <td>1.788857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.597200</td>\n",
       "      <td>1.742944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.545000</td>\n",
       "      <td>1.679608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.452300</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.358300</td>\n",
       "      <td>1.622527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.351000</td>\n",
       "      <td>1.500530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.327300</td>\n",
       "      <td>1.560745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='730' max='730' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [730/730 11:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set results: {'eval_loss': 2.1002368927001953, 'eval_runtime': 687.7496, 'eval_samples_per_second': 8.484, 'eval_steps_per_second': 1.061, 'epoch': 10.0}\n",
      "saving model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./fine-tuned-bert2/tokenizer_config.json',\n",
       " './fine-tuned-bert2/special_tokens_map.json',\n",
       " './fine-tuned-bert2/vocab.txt',\n",
       " './fine-tuned-bert2/added_tokens.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "# Load pre-trained BERT tokenizer and model\n",
    "print(\"loading tokenizer and model\")\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', clean_up_tokenization_spaces=True)\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load and preprocess dataset\n",
    "print(\"loading dataset\")\n",
    "dataset = load_dataset('text', data_files={'train': 'data/output_final.txt'}, split='train')\n",
    "\n",
    "# Calculate the split indices\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.8 * total_size)  # 80% for training\n",
    "val_size = int(0.1 * total_size)    # 10% for validation\n",
    "test_size = total_size - train_size - val_size  # 10% for testing\n",
    "\n",
    "# Create the splits manually without shuffling\n",
    "train_dataset = dataset.select(range(train_size))\n",
    "val_dataset = dataset.select(range(train_size, train_size + val_size))\n",
    "test_dataset = dataset.select(range(train_size + val_size, total_size))\n",
    "\n",
    "# Combine into a DatasetDict\n",
    "final_dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "\n",
    "# Tokenize the datasets\n",
    "print(\"tokenizing dataset\")\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['text'], \n",
    "        padding='max_length', \n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "tokenized_datasets = final_dataset.map(tokenize_function, batched=True, remove_columns=['text'])\n",
    "\n",
    "# Data collator for masked language modeling\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=True,\n",
    "    mlm_probability=0.15  # 15% of the tokens will be masked\n",
    ")\n",
    "\n",
    "# Define training arguments\n",
    "# print(\"defining training arguments\")\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir='./results',\n",
    "#     num_train_epochs=3,\n",
    "#     per_device_train_batch_size=8,\n",
    "#     per_device_eval_batch_size=8,\n",
    "#     warmup_steps=500,\n",
    "#     weight_decay=0.01,\n",
    "#     logging_dir='./logs',\n",
    "#     evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
    "#     save_strategy=\"epoch\",        # Save the model at the end of each epoch\n",
    "#     load_best_model_at_end=True,  # Load the best model when done\n",
    "# )\n",
    "\n",
    "print(\"defining training arguments\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,  # Adjust as needed\n",
    "    logging_dir='./logs',\n",
    "    eval_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
    "    save_strategy=\"epoch\",        # Save the model at the end of each epoch\n",
    "    load_best_model_at_end=True,  # Load the best model when done\n",
    "    learning_rate=5e-5,  # Lower learning rate\n",
    "    max_grad_norm=1.0,   # Prevent exploding gradients\n",
    "    logging_steps=500,\n",
    "    save_total_limit=1,  # Keep only the best model checkpoint\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "print(\"initializing trainer\")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    "    data_collator=data_collator  # Pass the data collator for MLM\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "print(\"fine-tuning model\")\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "print(\"evaluating model\")\n",
    "results = trainer.evaluate(tokenized_datasets['test'])\n",
    "\n",
    "print(f\"Test set results: {results}\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "print(\"saving model\")\n",
    "model.save_pretrained('./fine-tuned-bert2')\n",
    "tokenizer.save_pretrained('./fine-tuned-bert2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13 12:14:00.456652: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-13 12:14:00.564564: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-13 12:14:00.976011: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-13 12:14:00.976137: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-13 12:14:00.976142: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "760926417a9a4617b749dc5554c0ce2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40836 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61aebdb470fe44c8a9b2e6aca8c5da1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8751 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13aebb7de0d47eab618175e097e33fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8751 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15315' max='15315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15315/15315 24:42:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.363300</td>\n",
       "      <td>3.259553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.031300</td>\n",
       "      <td>3.158909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.801200</td>\n",
       "      <td>3.148474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1094' max='1094' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1094/1094 12:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.168238401412964,\n",
       " 'eval_runtime': 735.9012,\n",
       " 'eval_samples_per_second': 11.892,\n",
       " 'eval_steps_per_second': 1.487,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset\n",
    "from gtts import gTTS\n",
    "import os\n",
    "import torch\n",
    "from typing import List, Dict\n",
    "\n",
    "# Load pre-trained GPT-2 tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', clean_up_tokenization_spaces=True)\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load and preprocess dataset from a .txt file\n",
    "dataset = load_dataset('text', data_files={'train': './data/output_final.txt'}, split='train')\n",
    "\n",
    "# Manually split the dataset into training, validation, and test sets while preserving order\n",
    "split_ratio = 0.15  # 15% for validation, 15% for test\n",
    "split_index_val = int(len(dataset) * (1 - split_ratio))\n",
    "split_index_test = int(len(dataset) * (1 - 2 * split_ratio))\n",
    "train_dataset = Dataset.from_dict(dataset[:split_index_test])\n",
    "val_dataset = Dataset.from_dict(dataset[split_index_test:split_index_val])\n",
    "test_dataset = Dataset.from_dict(dataset[split_index_val:])\n",
    "\n",
    "# def preprocess_function(examples):\n",
    "#     return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=512)\n",
    "\n",
    "def preprocess_function(examples: List[str]) -> Dict[str, torch.Tensor]:\n",
    "    inputs = tokenizer(examples['text'], padding='max_length', truncation=True, max_length=512)\n",
    "    \n",
    "    # Create labels and set padding tokens in labels to -100 to ignore them in the loss\n",
    "    inputs['labels'] = inputs['input_ids'].copy()\n",
    "    inputs['labels'] = [[-100 if token == tokenizer.pad_token_id else token for token in label] for label in inputs['labels']]\n",
    "    \n",
    "    return inputs\n",
    "\n",
    "# tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=[\"text\"])\n",
    "tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True, remove_columns=[\"text\"])\n",
    "tokenized_val_dataset = val_dataset.map(preprocess_function, batched=True, remove_columns=[\"text\"])\n",
    "tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./resultsGPT2b',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logsGPT2b',\n",
    "    eval_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
    "    save_strategy=\"epoch\",        # Save the model at the end of each epoch\n",
    "    load_best_model_at_end=True,  # Load the best model when done\n",
    "    learning_rate=5e-5,  # Lower learning rate\n",
    "    max_grad_norm=1.0,   # Prevent exploding gradients\n",
    "    logging_steps=500,\n",
    "    save_total_limit=1,  # Keep only the best model checkpoint\n",
    ")\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir='./results',\n",
    "#     num_train_epochs=10,\n",
    "#     per_device_train_batch_size=8,\n",
    "#     per_device_eval_batch_size=8,\n",
    "#     warmup_steps=500,\n",
    "#     weight_decay=0.01,  # Adjust as needed\n",
    "#     logging_dir='./logs',\n",
    "#     eval_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
    "#     save_strategy=\"epoch\",        # Save the model at the end of each epoch\n",
    "#     load_best_model_at_end=True,  # Load the best model when done\n",
    "#     learning_rate=5e-5,  # Lower learning rate\n",
    "#     max_grad_norm=1.0,   # Prevent exploding gradients\n",
    "#     logging_steps=500,\n",
    "#     save_total_limit=1,  # Keep only the best model checkpoint\n",
    "# )\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    # train_dataset=tokenized_datasets,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained('./fine-tuned-gpt2')\n",
    "tokenizer.save_pretrained('./fine-tuned-gpt2')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "trainer.evaluate(eval_dataset=tokenized_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51050' max='51050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51050/51050 110:56:24, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.625100</td>\n",
       "      <td>3.140254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.446200</td>\n",
       "      <td>3.087585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.290900</td>\n",
       "      <td>3.063362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.076000</td>\n",
       "      <td>3.045647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.892300</td>\n",
       "      <td>3.125189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.733900</td>\n",
       "      <td>3.129887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.573000</td>\n",
       "      <td>3.179892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.503000</td>\n",
       "      <td>3.188739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.424900</td>\n",
       "      <td>3.218610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.384300</td>\n",
       "      <td>3.250127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./fine-tuned-gpt2-continued/tokenizer_config.json',\n",
       " './fine-tuned-gpt2-continued/special_tokens_map.json',\n",
       " './fine-tuned-gpt2-continued/vocab.json',\n",
       " './fine-tuned-gpt2-continued/merges.txt',\n",
       " './fine-tuned-gpt2-continued/added_tokens.json')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained('./fine-tuned-gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('./fine-tuned-gpt2')\n",
    "\n",
    "# Set the padding token to the EOS token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Define additional training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./resultsGPT2c',\n",
    "    num_train_epochs=10,  # Continue with additional epochs\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logsGPT2c',\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    learning_rate=5e-5,\n",
    "    max_grad_norm=1.0,\n",
    "    logging_steps=500,\n",
    "    save_total_limit=1,\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    ")\n",
    "\n",
    "# Continue fine-tuning the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained('./fine-tuned-gpt2-continued')\n",
    "tokenizer.save_pretrained('./fine-tuned-gpt2-continued')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1094' max='1094' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1094/1094 07:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.064765691757202,\n",
       " 'eval_runtime': 441.2436,\n",
       " 'eval_samples_per_second': 19.833,\n",
       " 'eval_steps_per_second': 2.479,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=tokenized_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the meaning of life? The meaning of God? The meaning of God? The meaning of God? The meaning of God? The meaning of God? The meaning of God? The meaning of God? The meaning of God? The meaning of God? The meaning of God? The meaning of God? The meaning of God? The meaning of God? The meaning of God? The meaning of God? The meaning of God? The meaning of God? The meaning of God? The meaning of God? The meaning of God? The meaning of God? The meaning of God? The meaning of God? The meaning of God? The meaning of God? The meaning of God? The meaning of God? The meaning of God? The meaning of\n"
     ]
    }
   ],
   "source": [
    "# Load the fine-tuned model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained('./fine-tuned-gpt2-continued')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('./fine-tuned-gpt2-continued')\n",
    "\n",
    "def generate_response(user_input):\n",
    "    inputs = tokenizer.encode(user_input, return_tensors='pt')\n",
    "    outputs = model.generate(inputs, max_length=150, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    return response\n",
    "\n",
    "# Example usage\n",
    "user_input = \"What is the meaning of life?\"\n",
    "response_text = generate_response(user_input)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the nature of God? Or is it just as good as the nature of man? Or is it just as bad? Or is it just as immoral? Or is it just as stupid? Or is it just as stupid? Or is it just as stupid? Or is it just as stupid? Or is it just as stupid? Or is it just as stupid? Or is it just as stupid? Or is it just as stupid? Or is it just as stupid? Or is it just as stupid? Or is it just as stupid? Or is it just as stupid? Or is it just as stupid? Or is it just as stupid? Or is it just as stupid? Or is it just as stupid? Or is it just as\n"
     ]
    }
   ],
   "source": [
    "user_input = \"What is the nature of God?\"\n",
    "response_text = generate_response(user_input)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_speech(text, filename='response.mp3'):\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "    tts.save(filename)\n",
    "    os.system(f\"mpg321 {filename}\")\n",
    "    \n",
    "text_to_speech(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, BertLMHeadModel\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "# model = BertForSequenceClassification.from_pretrained('./fine-tuned-bert2')\n",
    "model = BertLMHeadModel.from_pretrained('./fine-tuned-bert2')\n",
    "tokenizer = BertTokenizer.from_pretrained('./fine-tuned-bert2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(user_input):\n",
    "    inputs = tokenizer(user_input, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def generate_response(user_input):\n",
    "    inputs = preprocess_input(user_input)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    print(outputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class_id = torch.argmax(logits, dim=1).item()\n",
    "    return predicted_class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example mapping of class IDs to responses\n",
    "response_map = {\n",
    "    0: \"Response for class 0\",\n",
    "    1: \"Response for class 1\",\n",
    "    # Add more mappings as needed\n",
    "}\n",
    "\n",
    "def get_response_text(predicted_class_id):\n",
    "    return response_map.get(predicted_class_id, \"Sorry, I don't understand.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-0.0695, -0.1936]]), hidden_states=None, attentions=None)\n",
      "Response for class 0\n"
     ]
    }
   ],
   "source": [
    "def chat_bot_response(user_input):\n",
    "    predicted_class_id = generate_response(user_input)\n",
    "    response_text = get_response_text(predicted_class_id)\n",
    "    return response_text\n",
    "\n",
    "# Example usage\n",
    "user_input = \"What is the meaning of life?\"\n",
    "response = chat_bot_response(user_input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The current model class (BertForSequenceClassification) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'BertLMHeadModel'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m      8\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the meaning of life?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m response_text \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(response_text)\n",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m, in \u001b[0;36mgenerate_response\u001b[0;34m(user_input)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_response\u001b[39m(user_input):\n\u001b[1;32m      2\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(user_input, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     response \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda32/envs/awbot2/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda32/envs/awbot2/lib/python3.10/site-packages/transformers/generation/utils.py:1686\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1602\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1603\u001b[0m \n\u001b[1;32m   1604\u001b[0m \u001b[38;5;124;03mGenerates sequences of token ids for models with a language modeling head.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1683\u001b[0m \u001b[38;5;124;03m            - [`~generation.GenerateBeamEncoderDecoderOutput`]\u001b[39;00m\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1685\u001b[0m \u001b[38;5;66;03m# 1. Handle `generation_config` and kwargs that might update it, and validate the `.generate()` call\u001b[39;00m\n\u001b[0;32m-> 1686\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_model_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1687\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# Pull this out first, we only use it for stopping criteria\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m generation_config, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_generation_config(generation_config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda32/envs/awbot2/lib/python3.10/site-packages/transformers/generation/utils.py:1167\u001b[0m, in \u001b[0;36mGenerationMixin._validate_model_class\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generate_compatible_classes:\n\u001b[1;32m   1166\u001b[0m     exception_message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please use one of the following classes instead: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerate_compatible_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1167\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(exception_message)\n",
      "\u001b[0;31mTypeError\u001b[0m: The current model class (BertForSequenceClassification) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'BertLMHeadModel'}"
     ]
    }
   ],
   "source": [
    "def generate_response(user_input):\n",
    "    inputs = tokenizer.encode(user_input, return_tensors='pt')\n",
    "    outputs = model.generate(inputs, max_length=150, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# Example usage\n",
    "user_input = \"What is the meaning of life?\"\n",
    "response_text = generate_response(user_input)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-to-Speech Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Audio and Play"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
